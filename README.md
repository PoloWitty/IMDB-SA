> HUST AIA 2021 Fall Machine Learning Course

# IMDB情感分析任务

## 题目

**数据集**: IMDB数据集，包含来自互联网电影数据库（IMDB）的50000条严重两极分化的评论。数据集被分为用于训练的25000条评论和用于测试的25000条评论，训练集和测试集中都包括50%的正面评价和50%的负面评价。IMDB数据集内置于Keras库中，它已经过预处理，单词序列的评论已经被转换为整数序列，其中每个整数代表字典中的某个单词。

**任务**: 请在训练数据中选择前10000个最常出现的单词，并且在预训练的网络之上构建分类器。

**要求:**

- GRU、LSTM、Transformer、卷积神经网络任选一种或多种

- 必须提供Precision精确率、Recall召回率结果，其他评价指标也可附加。

## 作业结果

纵览整个大作业完成过程, 学习之处主要包括以下几个方面:

- 加深了对模型的理解程度
- 深入学习了pytorch库的使用, 如何构建网络, 如何训练, 如果使用tensorboard在训练时查看训练情况
- 自己构建了在IMDB文本上的tokenizer, 用于将原始的文本信息转换为模型能够接受的token\_id
- 亲自构建了基于LSTM模型的imdb情感分析任务模型并获得了相对较高的准确率
- 利用huggingface上预训练好的bert-base-uncased模型, 自己利用pytorch库完成了一次fine-tune任务, 并取得了相当不错的准确率


|                       | accuracy | precision | recall |
| --------------------- | -------- | --------- | ------ |
| 基于LSTM+残差连接结构 | 90.29%   | 89.79%    | 90.91% |
| fine-tuned BERT       | 93.48%   | 93.38%    | 93.60% |

## 其它

由于fine-tuned BERT的模型太大了, 无法直接上传到仓库, 所以只上传了基于LSTM+残差连接的模型的checkpoint, checkpoint标号最大的为accuracy最高的

